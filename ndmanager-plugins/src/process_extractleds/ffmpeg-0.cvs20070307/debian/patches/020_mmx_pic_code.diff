Index: ffmpeg-0.cvs20060724/libavcodec/i386/mpegvideo_mmx_template.c
===================================================================
--- ffmpeg-0.cvs20060724.orig/libavcodec/i386/mpegvideo_mmx_template.c	2006-07-24 17:11:17.000000000 +0200
+++ ffmpeg-0.cvs20060724/libavcodec/i386/mpegvideo_mmx_template.c	2006-07-24 17:22:08.000000000 +0200
@@ -108,7 +108,12 @@
             SPREADW(%%mm3)
             "pxor %%mm7, %%mm7                  \n\t" // 0
             "pxor %%mm4, %%mm4                  \n\t" // 0
+#if defined(PIC) && !defined(ARCH_X86_64)
+            "movl %2, %%"REG_a"                 \n\t"
+            "movq (%%"REG_a"), %%mm5            \n\t" // qmat[0]
+#else
             "movq (%2), %%mm5                   \n\t" // qmat[0]
+#endif
             "pxor %%mm6, %%mm6                  \n\t"
             "psubw (%3), %%mm6                  \n\t" // -bias[0]
             "mov $-128, %%"REG_a"               \n\t"
@@ -136,7 +141,11 @@
             "movd %%mm3, %%"REG_a"              \n\t"
             "movzb %%al, %%"REG_a"              \n\t" // last_non_zero_p1
             : "+a" (last_non_zero_p1)
+#if defined(PIC) && !defined(ARCH_X86_64)
+            : "r" (block+64), "m" (qmat), "r" (bias),
+#else
             : "r" (block+64), "r" (qmat), "r" (bias),
+#endif
               "r" (inv_zigzag_direct16+64), "r" (temp_block+64)
         );
         // note the asm is split cuz gcc doesnt like that many operands ...
@@ -150,6 +159,7 @@
         : "g" (s->max_qcoeff)
         );
     }else{ // FMT_H263
+	const uint16_t *qmat_64 = qmat + 64;
         asm volatile(
             "movd %%"REG_a", %%mm3              \n\t" // last_non_zero_p1
             SPREADW(%%mm3)
@@ -165,7 +175,13 @@
             "psubw %%mm1, %%mm0                 \n\t" // ABS(block[i])
             "movq (%3, %%"REG_a"), %%mm6        \n\t" // bias[0]
             "paddusw %%mm6, %%mm0               \n\t" // ABS(block[i]) + bias[0]
+#if defined(PIC) && !defined(ARCH_X86_64)
+            "addl %2, %%"REG_a"                 \n\t"
+            "movq (%%"REG_a"), %%mm5            \n\t" // qmat[i]
+            "subl %2, %%"REG_a"                 \n\t"
+#else
             "movq (%2, %%"REG_a"), %%mm5        \n\t" // qmat[i]
+#endif
             "pmulhw %%mm5, %%mm0                \n\t" // (ABS(block[i])*qmat[0] + bias[0]*qmat[0])>>16
             "por %%mm0, %%mm4                   \n\t"
             "pxor %%mm1, %%mm0                  \n\t"
@@ -182,7 +198,11 @@
             "movd %%mm3, %%"REG_a"              \n\t"
             "movzb %%al, %%"REG_a"              \n\t" // last_non_zero_p1
             : "+a" (last_non_zero_p1)
+#if defined(PIC) && !defined(ARCH_X86_64)
+            : "r" (block+64), "m" (qmat_64), "r" (bias+64),
+#else
             : "r" (block+64), "r" (qmat+64), "r" (bias+64),
+#endif
               "r" (inv_zigzag_direct16+64), "r" (temp_block+64)
         );
         // note the asm is split cuz gcc doesnt like that many operands ...
Index: ffmpeg-0.cvs20060724/libpostproc/postprocess_template.c
===================================================================
--- ffmpeg-0.cvs20060724.orig/libpostproc/postprocess_template.c	2006-06-11 14:17:36.000000000 +0200
+++ ffmpeg-0.cvs20060724/libpostproc/postprocess_template.c	2006-07-24 17:22:08.000000000 +0200
@@ -33,9 +33,11 @@
 #  define ALIGN_MASK "$0xFFFFFFFFFFFFFFF8"
 #else
 #  define REGa  eax
+#  define REGb  ebx
 #  define REGc  ecx
 #  define REGd  edx
 #  define REG_a  "eax"
+#  define REG_b  "ebx"
 #  define REG_c  "ecx"
 #  define REG_d  "edx"
 #  define REG_SP "esp"
@@ -3201,7 +3203,12 @@
                         "movq (%%"REG_a"), %%mm2        \n\t" // packedYOffset
                         "movq 8(%%"REG_a"), %%mm3       \n\t" // packedYScale
                         "lea (%2,%4), %%"REG_a"         \n\t"
+#if defined(PIC) && !defined(ARCH_X86_64)
+                        "push %%"REG_b"                 \n\t"
+                        "lea (%3,%5), %%"REG_b"         \n\t"
+#else
                         "lea (%3,%5), %%"REG_d"         \n\t"
+#endif
                         "pxor %%mm4, %%mm4              \n\t"
 #ifdef HAVE_MMX2
 #define REAL_SCALED_CPY(src1, src2, dst1, dst2)                                                \
@@ -3257,12 +3264,22 @@
 #define SCALED_CPY(src1, src2, dst1, dst2)\
    REAL_SCALED_CPY(src1, src2, dst1, dst2)
 
+#if defined(PIC) && !defined(ARCH_X86_64)
+SCALED_CPY((%2)       , (%2, %4)      , (%3)       , (%3, %5))
+SCALED_CPY((%2, %4, 2), (%%REGa, %4, 2), (%3, %5, 2), (%%REGb, %5, 2))
+SCALED_CPY((%2, %4, 4), (%%REGa, %4, 4), (%3, %5, 4), (%%REGb, %5, 4))
+                        "lea (%%"REG_a",%4,4), %%"REG_a"        \n\t"
+                        "lea (%%"REG_b",%5,4), %%"REG_b"        \n\t"
+SCALED_CPY((%%REGa, %4), (%%REGa, %4, 2), (%%REGb, %5), (%%REGb, %5, 2))
+                        "pop %%"REG_b"                          \n\t"
+#else
 SCALED_CPY((%2)       , (%2, %4)      , (%3)       , (%3, %5))
 SCALED_CPY((%2, %4, 2), (%%REGa, %4, 2), (%3, %5, 2), (%%REGd, %5, 2))
 SCALED_CPY((%2, %4, 4), (%%REGa, %4, 4), (%3, %5, 4), (%%REGd, %5, 4))
                         "lea (%%"REG_a",%4,4), %%"REG_a"        \n\t"
                         "lea (%%"REG_d",%5,4), %%"REG_d"        \n\t"
 SCALED_CPY((%%REGa, %4), (%%REGa, %4, 2), (%%REGd, %5), (%%REGd, %5, 2))
+#endif
 
 
                         : "=&a" (packedOffsetAndScale)
@@ -3271,7 +3288,10 @@
                         "r"(dst),
                         "r" ((long)srcStride),
                         "r" ((long)dstStride)
+#if defined(PIC) && !defined(ARCH_X86_64)
+#else
                         : "%"REG_d
+#endif
                                         );
 #else //HAVE_MMX
         for(i=0; i<8; i++)
@@ -3284,7 +3304,12 @@
 #ifdef HAVE_MMX
         asm volatile(
                 "lea (%0,%2), %%"REG_a"                 \n\t"
+#if defined(PIC) && !defined(ARCH_X86_64)
+                "push %%"REG_b"                         \n\t"
+                "lea (%1,%3), %%"REG_b"                 \n\t"
+#else
                 "lea (%1,%3), %%"REG_d"                 \n\t"
+#endif
 
 #define REAL_SIMPLE_CPY(src1, src2, dst1, dst2)                              \
                 "movq " #src1 ", %%mm0          \n\t"\
@@ -3295,18 +3320,32 @@
 #define SIMPLE_CPY(src1, src2, dst1, dst2)\
    REAL_SIMPLE_CPY(src1, src2, dst1, dst2)
 
+#if defined(PIC) && !defined(ARCH_X86_64)
+SIMPLE_CPY((%0)       , (%0, %2)      , (%1)       , (%1, %3))
+SIMPLE_CPY((%0, %2, 2), (%%REGa, %2, 2), (%1, %3, 2), (%%REGb, %3, 2))
+SIMPLE_CPY((%0, %2, 4), (%%REGa, %2, 4), (%1, %3, 4), (%%REGb, %3, 4))
+                "lea (%%"REG_a",%2,4), %%"REG_a"        \n\t"
+                "lea (%%"REG_b",%3,4), %%"REG_b"        \n\t"
+SIMPLE_CPY((%%REGa, %2), (%%REGa, %2, 2), (%%REGb, %3), (%%REGb, %3, 2))
+                "pop %%"REG_b"                          \n\t"
+#else
 SIMPLE_CPY((%0)       , (%0, %2)       , (%1)       , (%1, %3))
 SIMPLE_CPY((%0, %2, 2), (%%REGa, %2, 2), (%1, %3, 2), (%%REGd, %3, 2))
 SIMPLE_CPY((%0, %2, 4), (%%REGa, %2, 4), (%1, %3, 4), (%%REGd, %3, 4))
                 "lea (%%"REG_a",%2,4), %%"REG_a"        \n\t"
                 "lea (%%"REG_d",%3,4), %%"REG_d"        \n\t"
 SIMPLE_CPY((%%REGa, %2), (%%REGa, %2, 2), (%%REGd, %3), (%%REGd, %3, 2))
+#endif
 
                 : : "r" (src),
                 "r" (dst),
                 "r" ((long)srcStride),
                 "r" ((long)dstStride)
+#if defined(PIC) && !defined(ARCH_X86_64)
+                : "%"REG_a
+#else
                 : "%"REG_a, "%"REG_d
+#endif
         );
 #else //HAVE_MMX
         for(i=0; i<8; i++)
